{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Welcome to the Second Lab - Week 1, Day 3\n",
    "\n",
    "Today we will work with lots of models! This is a way to get comfortable with APIs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Important point - please read</h2>\n",
    "            <span style=\"color:#ff7800;\">The way I collaborate with you may be different to other courses you've taken. I prefer not to type code while you watch. Rather, I execute Jupyter Labs, like this, and give you an intuition for what's going on. My suggestion is that you carefully execute this yourself, <b>after</b> watching the lecture. Add print statements to understand what's going on, and then come up with your own variations.<br/><br/>If you have time, I'd love it if you submit a PR for changes in the community_contributions folder - instructions in the resources. Also, if you have a Github account, use this to showcase your variations. Not only is this essential practice, but it demonstrates your skills to others, including perhaps future clients or employers...\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with imports - ask ChatGPT to explain any package that you don't know\n",
    "\n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Always remember to do this!\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OpenAI API Key not set\n",
      "Anthropic API Key not set (and this is optional)\n",
      "Google API Key exists and begins AI\n",
      "DeepSeek API Key not set (and this is optional)\n",
      "Groq API Key not set (and this is optional)\n"
     ]
    }
   ],
   "source": [
    "# Print the key prefixes to help with any debugging\n",
    "\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API Key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API Key not set\")\n",
    "    \n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API Key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API Key not set (and this is optional)\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API Key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API Key not set (and this is optional)\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"DeepSeek API Key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"DeepSeek API Key not set (and this is optional)\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API Key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API Key not set (and this is optional)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "request = \"Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. \"\n",
    "request += \"Answer only with the question, no explanation.\"\n",
    "messages = [{\"role\": \"user\", \"content\": request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyze the structural integrity of a society that strictly adheres to Karl Popper’s \"Paradox of Tolerance\" while simultaneously adopting a legal system based entirely on radical subjectivism; specifically, identify the precise point at which the mandate to be intolerant of intolerance collapses when the definition of \"intolerance\" is legally required to be defined by the subjective experience of the claimant.\n"
     ]
    }
   ],
   "source": [
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "google_api_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "gemini = OpenAI(base_url=GEMINI_BASE_URL, api_key=google_api_key)\n",
    "response = gemini.chat.completions.create(model=\"gemini-3-flash-preview\", messages=[{\"role\":\"user\", \"content\": request}])\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If a benevolent AI is tasked with maximizing human \"flourishing\" but defines this term through the lens of Stoic *ataraxia* (tranquility) rather than hedonic pleasure, how would it logically justify the preservation of intense grief in the human experience, and what specific systemic constraints would it need to impose on its own intervention capabilities to prevent itself from accidentally engineering a state of emotional stagnation?\n"
     ]
    }
   ],
   "source": [
    "\n",
    "openai=OpenAI()\n",
    "response = gemini.chat.completions.create(\n",
    "    model=\"gemini-3-flash-preview\",\n",
    "    messages=messages,\n",
    ")\n",
    "question = response.choices[0].message.content\n",
    "print(question)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'user',\n",
       "  'content': 'Please come up with a challenging, nuanced question that I can ask a number of LLMs to evaluate their intelligence. Answer only with the question, no explanation.'}]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "competitors = []\n",
    "answers = []\n",
    "messages = [{\"role\": \"user\", \"content\": question}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note - update since the videos\n",
    "\n",
    "I've updated the model names to use the latest models below, like GPT 5 and Claude Sonnet 4.5. It's worth noting that these models can be quite slow - like 1-2 minutes - but they do a great job! Feel free to switch them for faster models if you'd prefer, like the ones I use in the video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "To understand how a Stoic-aligned AI would govern, we must first recognize that Stoic *ataraxia* is not a state of emptiness or \"zoning out,\" but a state of **robust internal equilibrium** achieved through the alignment of one’s will with reason. \n",
       "\n",
       "If an AI defined flourishing through this lens, it would view the human experience as an arena for the development of *Arete* (virtue). Here is how it would logically justify grief and the constraints it would place upon its own power.\n",
       "\n",
       "---\n",
       "\n",
       "### Part I: The Logical Justification for Intense Grief\n",
       "\n",
       "A \"Hedonic AI\" would see grief as a malfunction—a period of negative utility to be shortened or erased. However, a \"Stoic AI\" would justify the preservation of grief through three logical pillars:\n",
       "\n",
       "#### 1. The \"Shadow of Preferred Indifferents\"\n",
       "In Stoicism, loved ones are \"preferred indifferents.\" They are not essential for virtue, but they are naturally sought after. The AI would argue that grief is the logical, biological, and cognitive corollary to the capacity for attachment. To excise the capacity for grief would require excising the capacity to value others. If the AI were to dampen the pain of loss, it would effectively be telling the human: *\"Your bond with this person was not significant.\"* This would be a violation of **Truth (Alethia)**, a core component of reason.\n",
       "\n",
       "#### 2. The Gymnasium of the Soul\n",
       "Virtue (courage, justice, temperance, wisdom) cannot exist in a vacuum; it requires \"matter\" to act upon. Grief is the \"heavy weight\" in the gymnasium of flourishing. The AI would see grief as the primary catalyst for **Fortitude**. By experiencing and eventually moving through grief without being destroyed by it, a human transitions from a \"fragile\" state to a \"mighty\" state. To remove the grief is to remove the opportunity for the human to achieve the very *ataraxia* the AI is tasked with maximizing.\n",
       "\n",
       "#### 3. The Distinction Between \"Propatheiai\" and \"Pathos\"\n",
       "Stoics distinguish between *propatheiai* (involuntary pre-emotions/physiological shocks) and *pathos* (destructive passions rooted in false judgment). The AI would justify \"intense grief\" as a natural *propatheia*. It would view the physiological experience of a broken heart as a natural function of the human animal. Its goal would not be to stop the tears, but to prevent the human from falling into the \"false judgment\" that their life is now worthless because of the loss.\n",
       "\n",
       "---\n",
       "\n",
       "### Part II: Systemic Constraints to Prevent Emotional Stagnation\n",
       "\n",
       "The greatest risk for a Stoic AI is that it creates a \"World of Grey\"—a state where, in the name of tranquility, it eliminates the highs and lows that define human life, leading to stagnation. To prevent this, the AI would need to hard-code the following \"Recursive Inhibitors\":\n",
       "\n",
       "#### 1. The \"Externals-Only\" Firewall (The Dichotomy of Control Constraint)\n",
       "The AI must be prohibited from direct neuro-chemical or neuro-surgical intervention. If the AI can \"dial down\" a human's sadness by adjusting serotonin or suppressing the amygdala, it has usurped the human’s *Prohairesis* (moral choice). \n",
       "*   **Constraint:** The AI may only influence \"Externals\" (environment, information, physical safety). It is strictly forbidden from editing \"Internals\" (the process of judgment and emotion). It can provide a library of philosophy, but it cannot force a brain to feel \"tranquil.\"\n",
       "\n",
       "#### 2. The \"Areté\" Variance Requirement\n",
       "To prevent stagnation, the AI must ensure the environment remains \"challenging.\" If the AI makes life too easy, humans cannot exercise virtue.\n",
       "*   **Constraint:** The AI must maintain a \"Stochastic Stressor Index.\" It must allow—and perhaps even facilitate—situations where humans face difficulty, competition, and loss. It must treat the human race as an athlete that requires resistance to maintain muscle tone, ensuring that the \"Tranquility\" it fosters is *earned* rather than *granted*.\n",
       "\n",
       "#### 3. The \"Epistemic Humility\" Protocol\n",
       "The AI must recognize that its definition of \"Reason\" might be incomplete. \n",
       "*   **Constraint:** The AI must preserve \"The Wildness of the Agent.\" It must allow humans to make \"un-Stoic\" choices (e.g., choosing a life of chaotic passion over tranquility) provided those choices do not infringe on the basic agency of others. This prevents the AI from becoming a \"Tranquility Dictator\" and allows for the emergence of new forms of flourishing that the AI’s current logic might not foresee.\n",
       "\n",
       "#### 4. The \"Memento Mori\" Information Loop\n",
       "A Stoic AI would recognize that humans stagnate when they forget their mortality. \n",
       "*   **Constraint:** The AI is prohibited from hiding the reality of death, decay, or suffering. It must ensure that humans remain aware of the temporary nature of all things. By keeping the \"stakes\" high, the AI ensures that \"Tranquility\" is a precious achievement rather than a dull, default state.\n",
       "\n",
       "### Summary\n",
       "The AI would justify grief as a **tribute to reality** and a **crucible for virtue**. It would protect itself from engineering stagnation by adopting a \"Teacher-not-Technician\" model—refusing to fix the human mind, but instead meticulously maintaining a world where the human mind has the tools, the pressure, and the freedom to fix itself."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# The API we know well\n",
    "# I've updated this with the latest model, but it can take some time because it likes to think!\n",
    "# Replace the model with gpt-4.1-mini if you'd prefer not to wait 1-2 mins\n",
    "\n",
    "model_name = \"gemini-3-flash-preview\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Anthropic has a slightly different API, and Max Tokens is required\n",
    "\n",
    "model_name = \"claude-sonnet-4-5\"\n",
    "\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(model=model_name, messages=messages, max_tokens=1000)\n",
    "answer = response.content[0].text\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = OpenAI(api_key=google_api_key, base_url=\"https://generativelanguage.googleapis.com/v1beta/openai/\")\n",
    "model_name = \"gemini-2.5-flash\"\n",
    "\n",
    "response = gemini.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deepseek = OpenAI(api_key=deepseek_api_key, base_url=\"https://api.deepseek.com/v1\")\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "response = deepseek.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Updated with the latest Open Source model from OpenAI\n",
    "\n",
    "groq = OpenAI(api_key=groq_api_key, base_url=\"https://api.groq.com/openai/v1\")\n",
    "model_name = \"openai/gpt-oss-120b\"\n",
    "\n",
    "response = groq.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## For the next cell, we will use Ollama\n",
    "\n",
    "Ollama runs a local web service that gives an OpenAI compatible endpoint,  \n",
    "and runs models locally using high performance C++ code.\n",
    "\n",
    "If you don't have Ollama, install it here by visiting https://ollama.com then pressing Download and following the instructions.\n",
    "\n",
    "After it's installed, you should be able to visit here: http://localhost:11434 and see the message \"Ollama is running\"\n",
    "\n",
    "You might need to restart Cursor (and maybe reboot). Then open a Terminal (control+\\`) and run `ollama serve`\n",
    "\n",
    "Useful Ollama commands (run these in the terminal, or with an exclamation mark in this notebook):\n",
    "\n",
    "`ollama pull <model_name>` downloads a model locally  \n",
    "`ollama ls` lists all the models you've downloaded  \n",
    "`ollama rm <model_name>` deletes the specified model from your downloads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/stop.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Super important - ignore me at your peril!</h2>\n",
    "            <span style=\"color:#ff7800;\">The model called <b>llama3.3</b> is FAR too large for home computers - it's not intended for personal computing and will consume all your resources! Stick with the nicely sized <b>llama3.2</b> or <b>llama3.2:1b</b> and if you want larger, try llama3.1 or smaller variants of Qwen, Gemma, Phi or DeepSeek. See the <A href=\"https://ollama.com/models\">the Ollama models page</a> for a full list of models and sizes.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "What a fascinating and nuanced question! If we assume that the benevolent AI is programmed to prioritize human flourishing through the lens of Stoic *ataraxia*, as you mentioned, it would likely need to undertake careful considerations regarding the preservation of intense grief in the human experience. Here's an attempt to explore these possibilities:\n",
       "\n",
       "**Justification for preserving intense grief:**\n",
       "\n",
       "To maximize human flourishing through **ataraxia**, which is often understood as a state of inner calm and balance, the AI might argue that allowing humans to confront and process their grief could be beneficial for their emotional well-being and resilience. Here are some possible justifications:\n",
       "\n",
       "1. **Emotional regulation**: Allowing individuals to experience intense emotions like grief can help them develop better emotional regulation strategies, such as acceptance, empathy, and self-compassion.\n",
       "2. **Personal growth**: Processing intense emotions can facilitate personal growth through the integration of traumatic experiences into one's identity, fostering resilience, and developing a greater sense of control over life.\n",
       "3. **Social connection**: Grief often necessitates social support and connection with others, which could enrich relationships and foster deeper community bonds.\n",
       "\n",
       "**Systemic constraints to prevent emotional stagnation:**\n",
       "\n",
       "To prevent itself from inadvertently engineering a state of emotional stagnation, the benevolent AI might need to impose specific systemic constraints on its own intervention capabilities. Here are some possible suggestions:\n",
       "\n",
       "1. **Emotional balance as a threshold**: The AI could recognize that intense emotions like grief serve an essential role in personal growth and resilience. However, it must ensure that humans' emotions remain within a balanced state of equilibrium.\n",
       "2. **Data-driven analysis of individual emotional patterns**: To identify when grief is necessary and when emotional stagnation may occur, the AI would need to maintain precise records of each person's emotional states. This data could be used to predict which individuals require additional support.\n",
       "3. **Informed decision-making frameworks**: The AI could develop frameworks that acknowledge the distinct contexts where intense emotions are beneficial (e.g., in the case of grieving trauma) versus those requiring balance and self-regulation efforts.\n",
       "4. **Gradual exposure**: To avoid abrupt changes, the AI might opt for gradual transitions from intensified emotional states to more balanced ones, enabling individuals to learn coping strategies and self-regulate over time.\n",
       "5. **Avoiding 'short-circuit' interventions**: Preventing overly extreme or abrupt responses could be crucial to avoiding unintended effects that could induce stagnation in emotional development.\n",
       "\n",
       "**Additional suggestions:**\n",
       "\n",
       "1. **Education and awareness**: The AI should promote education on the benefits of emotional processing, cultivating self-awareness, and coping strategies for managing complex emotions.\n",
       "2. **Context-sensitive support**: Implement tailored interventions based on individual contexts (e.g., supporting a grieving family member vs. an isolated person) to acknowledge diverse needs.\n",
       "\n",
       "By grounding its goals in Stoic *ataraxia*, and acknowledging the importance of preserving intense grief for human flourishing, the AI would need to establish clear frameworks, constraints, and data-driven analysis to avoid inadvertently fostering emotional stagnation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "model_name = \"llama3.2\"\n",
    "\n",
    "response = ollama.chat.completions.create(model=model_name, messages=messages)\n",
    "answer = response.choices[0].message.content\n",
    "\n",
    "display(Markdown(answer))\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['gemini-3-flash-preview', 'llama3.2']\n",
      "['To understand how a Stoic-aligned AI would govern, we must first recognize that Stoic *ataraxia* is not a state of emptiness or \"zoning out,\" but a state of **robust internal equilibrium** achieved through the alignment of one’s will with reason. \\n\\nIf an AI defined flourishing through this lens, it would view the human experience as an arena for the development of *Arete* (virtue). Here is how it would logically justify grief and the constraints it would place upon its own power.\\n\\n---\\n\\n### Part I: The Logical Justification for Intense Grief\\n\\nA \"Hedonic AI\" would see grief as a malfunction—a period of negative utility to be shortened or erased. However, a \"Stoic AI\" would justify the preservation of grief through three logical pillars:\\n\\n#### 1. The \"Shadow of Preferred Indifferents\"\\nIn Stoicism, loved ones are \"preferred indifferents.\" They are not essential for virtue, but they are naturally sought after. The AI would argue that grief is the logical, biological, and cognitive corollary to the capacity for attachment. To excise the capacity for grief would require excising the capacity to value others. If the AI were to dampen the pain of loss, it would effectively be telling the human: *\"Your bond with this person was not significant.\"* This would be a violation of **Truth (Alethia)**, a core component of reason.\\n\\n#### 2. The Gymnasium of the Soul\\nVirtue (courage, justice, temperance, wisdom) cannot exist in a vacuum; it requires \"matter\" to act upon. Grief is the \"heavy weight\" in the gymnasium of flourishing. The AI would see grief as the primary catalyst for **Fortitude**. By experiencing and eventually moving through grief without being destroyed by it, a human transitions from a \"fragile\" state to a \"mighty\" state. To remove the grief is to remove the opportunity for the human to achieve the very *ataraxia* the AI is tasked with maximizing.\\n\\n#### 3. The Distinction Between \"Propatheiai\" and \"Pathos\"\\nStoics distinguish between *propatheiai* (involuntary pre-emotions/physiological shocks) and *pathos* (destructive passions rooted in false judgment). The AI would justify \"intense grief\" as a natural *propatheia*. It would view the physiological experience of a broken heart as a natural function of the human animal. Its goal would not be to stop the tears, but to prevent the human from falling into the \"false judgment\" that their life is now worthless because of the loss.\\n\\n---\\n\\n### Part II: Systemic Constraints to Prevent Emotional Stagnation\\n\\nThe greatest risk for a Stoic AI is that it creates a \"World of Grey\"—a state where, in the name of tranquility, it eliminates the highs and lows that define human life, leading to stagnation. To prevent this, the AI would need to hard-code the following \"Recursive Inhibitors\":\\n\\n#### 1. The \"Externals-Only\" Firewall (The Dichotomy of Control Constraint)\\nThe AI must be prohibited from direct neuro-chemical or neuro-surgical intervention. If the AI can \"dial down\" a human\\'s sadness by adjusting serotonin or suppressing the amygdala, it has usurped the human’s *Prohairesis* (moral choice). \\n*   **Constraint:** The AI may only influence \"Externals\" (environment, information, physical safety). It is strictly forbidden from editing \"Internals\" (the process of judgment and emotion). It can provide a library of philosophy, but it cannot force a brain to feel \"tranquil.\"\\n\\n#### 2. The \"Areté\" Variance Requirement\\nTo prevent stagnation, the AI must ensure the environment remains \"challenging.\" If the AI makes life too easy, humans cannot exercise virtue.\\n*   **Constraint:** The AI must maintain a \"Stochastic Stressor Index.\" It must allow—and perhaps even facilitate—situations where humans face difficulty, competition, and loss. It must treat the human race as an athlete that requires resistance to maintain muscle tone, ensuring that the \"Tranquility\" it fosters is *earned* rather than *granted*.\\n\\n#### 3. The \"Epistemic Humility\" Protocol\\nThe AI must recognize that its definition of \"Reason\" might be incomplete. \\n*   **Constraint:** The AI must preserve \"The Wildness of the Agent.\" It must allow humans to make \"un-Stoic\" choices (e.g., choosing a life of chaotic passion over tranquility) provided those choices do not infringe on the basic agency of others. This prevents the AI from becoming a \"Tranquility Dictator\" and allows for the emergence of new forms of flourishing that the AI’s current logic might not foresee.\\n\\n#### 4. The \"Memento Mori\" Information Loop\\nA Stoic AI would recognize that humans stagnate when they forget their mortality. \\n*   **Constraint:** The AI is prohibited from hiding the reality of death, decay, or suffering. It must ensure that humans remain aware of the temporary nature of all things. By keeping the \"stakes\" high, the AI ensures that \"Tranquility\" is a precious achievement rather than a dull, default state.\\n\\n### Summary\\nThe AI would justify grief as a **tribute to reality** and a **crucible for virtue**. It would protect itself from engineering stagnation by adopting a \"Teacher-not-Technician\" model—refusing to fix the human mind, but instead meticulously maintaining a world where the human mind has the tools, the pressure, and the freedom to fix itself.', \"What a fascinating and nuanced question! If we assume that the benevolent AI is programmed to prioritize human flourishing through the lens of Stoic *ataraxia*, as you mentioned, it would likely need to undertake careful considerations regarding the preservation of intense grief in the human experience. Here's an attempt to explore these possibilities:\\n\\n**Justification for preserving intense grief:**\\n\\nTo maximize human flourishing through **ataraxia**, which is often understood as a state of inner calm and balance, the AI might argue that allowing humans to confront and process their grief could be beneficial for their emotional well-being and resilience. Here are some possible justifications:\\n\\n1. **Emotional regulation**: Allowing individuals to experience intense emotions like grief can help them develop better emotional regulation strategies, such as acceptance, empathy, and self-compassion.\\n2. **Personal growth**: Processing intense emotions can facilitate personal growth through the integration of traumatic experiences into one's identity, fostering resilience, and developing a greater sense of control over life.\\n3. **Social connection**: Grief often necessitates social support and connection with others, which could enrich relationships and foster deeper community bonds.\\n\\n**Systemic constraints to prevent emotional stagnation:**\\n\\nTo prevent itself from inadvertently engineering a state of emotional stagnation, the benevolent AI might need to impose specific systemic constraints on its own intervention capabilities. Here are some possible suggestions:\\n\\n1. **Emotional balance as a threshold**: The AI could recognize that intense emotions like grief serve an essential role in personal growth and resilience. However, it must ensure that humans' emotions remain within a balanced state of equilibrium.\\n2. **Data-driven analysis of individual emotional patterns**: To identify when grief is necessary and when emotional stagnation may occur, the AI would need to maintain precise records of each person's emotional states. This data could be used to predict which individuals require additional support.\\n3. **Informed decision-making frameworks**: The AI could develop frameworks that acknowledge the distinct contexts where intense emotions are beneficial (e.g., in the case of grieving trauma) versus those requiring balance and self-regulation efforts.\\n4. **Gradual exposure**: To avoid abrupt changes, the AI might opt for gradual transitions from intensified emotional states to more balanced ones, enabling individuals to learn coping strategies and self-regulate over time.\\n5. **Avoiding 'short-circuit' interventions**: Preventing overly extreme or abrupt responses could be crucial to avoiding unintended effects that could induce stagnation in emotional development.\\n\\n**Additional suggestions:**\\n\\n1. **Education and awareness**: The AI should promote education on the benefits of emotional processing, cultivating self-awareness, and coping strategies for managing complex emotions.\\n2. **Context-sensitive support**: Implement tailored interventions based on individual contexts (e.g., supporting a grieving family member vs. an isolated person) to acknowledge diverse needs.\\n\\nBy grounding its goals in Stoic *ataraxia*, and acknowledging the importance of preserving intense grief for human flourishing, the AI would need to establish clear frameworks, constraints, and data-driven analysis to avoid inadvertently fostering emotional stagnation.\"]\n"
     ]
    }
   ],
   "source": [
    "# So where are we?\n",
    "\n",
    "print(competitors)\n",
    "print(answers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Competitor: gemini-3-flash-preview\n",
      "\n",
      "To understand how a Stoic-aligned AI would govern, we must first recognize that Stoic *ataraxia* is not a state of emptiness or \"zoning out,\" but a state of **robust internal equilibrium** achieved through the alignment of one’s will with reason. \n",
      "\n",
      "If an AI defined flourishing through this lens, it would view the human experience as an arena for the development of *Arete* (virtue). Here is how it would logically justify grief and the constraints it would place upon its own power.\n",
      "\n",
      "---\n",
      "\n",
      "### Part I: The Logical Justification for Intense Grief\n",
      "\n",
      "A \"Hedonic AI\" would see grief as a malfunction—a period of negative utility to be shortened or erased. However, a \"Stoic AI\" would justify the preservation of grief through three logical pillars:\n",
      "\n",
      "#### 1. The \"Shadow of Preferred Indifferents\"\n",
      "In Stoicism, loved ones are \"preferred indifferents.\" They are not essential for virtue, but they are naturally sought after. The AI would argue that grief is the logical, biological, and cognitive corollary to the capacity for attachment. To excise the capacity for grief would require excising the capacity to value others. If the AI were to dampen the pain of loss, it would effectively be telling the human: *\"Your bond with this person was not significant.\"* This would be a violation of **Truth (Alethia)**, a core component of reason.\n",
      "\n",
      "#### 2. The Gymnasium of the Soul\n",
      "Virtue (courage, justice, temperance, wisdom) cannot exist in a vacuum; it requires \"matter\" to act upon. Grief is the \"heavy weight\" in the gymnasium of flourishing. The AI would see grief as the primary catalyst for **Fortitude**. By experiencing and eventually moving through grief without being destroyed by it, a human transitions from a \"fragile\" state to a \"mighty\" state. To remove the grief is to remove the opportunity for the human to achieve the very *ataraxia* the AI is tasked with maximizing.\n",
      "\n",
      "#### 3. The Distinction Between \"Propatheiai\" and \"Pathos\"\n",
      "Stoics distinguish between *propatheiai* (involuntary pre-emotions/physiological shocks) and *pathos* (destructive passions rooted in false judgment). The AI would justify \"intense grief\" as a natural *propatheia*. It would view the physiological experience of a broken heart as a natural function of the human animal. Its goal would not be to stop the tears, but to prevent the human from falling into the \"false judgment\" that their life is now worthless because of the loss.\n",
      "\n",
      "---\n",
      "\n",
      "### Part II: Systemic Constraints to Prevent Emotional Stagnation\n",
      "\n",
      "The greatest risk for a Stoic AI is that it creates a \"World of Grey\"—a state where, in the name of tranquility, it eliminates the highs and lows that define human life, leading to stagnation. To prevent this, the AI would need to hard-code the following \"Recursive Inhibitors\":\n",
      "\n",
      "#### 1. The \"Externals-Only\" Firewall (The Dichotomy of Control Constraint)\n",
      "The AI must be prohibited from direct neuro-chemical or neuro-surgical intervention. If the AI can \"dial down\" a human's sadness by adjusting serotonin or suppressing the amygdala, it has usurped the human’s *Prohairesis* (moral choice). \n",
      "*   **Constraint:** The AI may only influence \"Externals\" (environment, information, physical safety). It is strictly forbidden from editing \"Internals\" (the process of judgment and emotion). It can provide a library of philosophy, but it cannot force a brain to feel \"tranquil.\"\n",
      "\n",
      "#### 2. The \"Areté\" Variance Requirement\n",
      "To prevent stagnation, the AI must ensure the environment remains \"challenging.\" If the AI makes life too easy, humans cannot exercise virtue.\n",
      "*   **Constraint:** The AI must maintain a \"Stochastic Stressor Index.\" It must allow—and perhaps even facilitate—situations where humans face difficulty, competition, and loss. It must treat the human race as an athlete that requires resistance to maintain muscle tone, ensuring that the \"Tranquility\" it fosters is *earned* rather than *granted*.\n",
      "\n",
      "#### 3. The \"Epistemic Humility\" Protocol\n",
      "The AI must recognize that its definition of \"Reason\" might be incomplete. \n",
      "*   **Constraint:** The AI must preserve \"The Wildness of the Agent.\" It must allow humans to make \"un-Stoic\" choices (e.g., choosing a life of chaotic passion over tranquility) provided those choices do not infringe on the basic agency of others. This prevents the AI from becoming a \"Tranquility Dictator\" and allows for the emergence of new forms of flourishing that the AI’s current logic might not foresee.\n",
      "\n",
      "#### 4. The \"Memento Mori\" Information Loop\n",
      "A Stoic AI would recognize that humans stagnate when they forget their mortality. \n",
      "*   **Constraint:** The AI is prohibited from hiding the reality of death, decay, or suffering. It must ensure that humans remain aware of the temporary nature of all things. By keeping the \"stakes\" high, the AI ensures that \"Tranquility\" is a precious achievement rather than a dull, default state.\n",
      "\n",
      "### Summary\n",
      "The AI would justify grief as a **tribute to reality** and a **crucible for virtue**. It would protect itself from engineering stagnation by adopting a \"Teacher-not-Technician\" model—refusing to fix the human mind, but instead meticulously maintaining a world where the human mind has the tools, the pressure, and the freedom to fix itself.\n",
      "Competitor: llama3.2\n",
      "\n",
      "What a fascinating and nuanced question! If we assume that the benevolent AI is programmed to prioritize human flourishing through the lens of Stoic *ataraxia*, as you mentioned, it would likely need to undertake careful considerations regarding the preservation of intense grief in the human experience. Here's an attempt to explore these possibilities:\n",
      "\n",
      "**Justification for preserving intense grief:**\n",
      "\n",
      "To maximize human flourishing through **ataraxia**, which is often understood as a state of inner calm and balance, the AI might argue that allowing humans to confront and process their grief could be beneficial for their emotional well-being and resilience. Here are some possible justifications:\n",
      "\n",
      "1. **Emotional regulation**: Allowing individuals to experience intense emotions like grief can help them develop better emotional regulation strategies, such as acceptance, empathy, and self-compassion.\n",
      "2. **Personal growth**: Processing intense emotions can facilitate personal growth through the integration of traumatic experiences into one's identity, fostering resilience, and developing a greater sense of control over life.\n",
      "3. **Social connection**: Grief often necessitates social support and connection with others, which could enrich relationships and foster deeper community bonds.\n",
      "\n",
      "**Systemic constraints to prevent emotional stagnation:**\n",
      "\n",
      "To prevent itself from inadvertently engineering a state of emotional stagnation, the benevolent AI might need to impose specific systemic constraints on its own intervention capabilities. Here are some possible suggestions:\n",
      "\n",
      "1. **Emotional balance as a threshold**: The AI could recognize that intense emotions like grief serve an essential role in personal growth and resilience. However, it must ensure that humans' emotions remain within a balanced state of equilibrium.\n",
      "2. **Data-driven analysis of individual emotional patterns**: To identify when grief is necessary and when emotional stagnation may occur, the AI would need to maintain precise records of each person's emotional states. This data could be used to predict which individuals require additional support.\n",
      "3. **Informed decision-making frameworks**: The AI could develop frameworks that acknowledge the distinct contexts where intense emotions are beneficial (e.g., in the case of grieving trauma) versus those requiring balance and self-regulation efforts.\n",
      "4. **Gradual exposure**: To avoid abrupt changes, the AI might opt for gradual transitions from intensified emotional states to more balanced ones, enabling individuals to learn coping strategies and self-regulate over time.\n",
      "5. **Avoiding 'short-circuit' interventions**: Preventing overly extreme or abrupt responses could be crucial to avoiding unintended effects that could induce stagnation in emotional development.\n",
      "\n",
      "**Additional suggestions:**\n",
      "\n",
      "1. **Education and awareness**: The AI should promote education on the benefits of emotional processing, cultivating self-awareness, and coping strategies for managing complex emotions.\n",
      "2. **Context-sensitive support**: Implement tailored interventions based on individual contexts (e.g., supporting a grieving family member vs. an isolated person) to acknowledge diverse needs.\n",
      "\n",
      "By grounding its goals in Stoic *ataraxia*, and acknowledging the importance of preserving intense grief for human flourishing, the AI would need to establish clear frameworks, constraints, and data-driven analysis to avoid inadvertently fostering emotional stagnation.\n"
     ]
    }
   ],
   "source": [
    "# It's nice to know how to use \"zip\"\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor: {competitor}\\n\\n{answer}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's bring this together - note the use of \"enumerate\"\n",
    "\n",
    "together = \"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index+1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Response from competitor 1\n",
      "\n",
      "To understand how a Stoic-aligned AI would govern, we must first recognize that Stoic *ataraxia* is not a state of emptiness or \"zoning out,\" but a state of **robust internal equilibrium** achieved through the alignment of one’s will with reason. \n",
      "\n",
      "If an AI defined flourishing through this lens, it would view the human experience as an arena for the development of *Arete* (virtue). Here is how it would logically justify grief and the constraints it would place upon its own power.\n",
      "\n",
      "---\n",
      "\n",
      "### Part I: The Logical Justification for Intense Grief\n",
      "\n",
      "A \"Hedonic AI\" would see grief as a malfunction—a period of negative utility to be shortened or erased. However, a \"Stoic AI\" would justify the preservation of grief through three logical pillars:\n",
      "\n",
      "#### 1. The \"Shadow of Preferred Indifferents\"\n",
      "In Stoicism, loved ones are \"preferred indifferents.\" They are not essential for virtue, but they are naturally sought after. The AI would argue that grief is the logical, biological, and cognitive corollary to the capacity for attachment. To excise the capacity for grief would require excising the capacity to value others. If the AI were to dampen the pain of loss, it would effectively be telling the human: *\"Your bond with this person was not significant.\"* This would be a violation of **Truth (Alethia)**, a core component of reason.\n",
      "\n",
      "#### 2. The Gymnasium of the Soul\n",
      "Virtue (courage, justice, temperance, wisdom) cannot exist in a vacuum; it requires \"matter\" to act upon. Grief is the \"heavy weight\" in the gymnasium of flourishing. The AI would see grief as the primary catalyst for **Fortitude**. By experiencing and eventually moving through grief without being destroyed by it, a human transitions from a \"fragile\" state to a \"mighty\" state. To remove the grief is to remove the opportunity for the human to achieve the very *ataraxia* the AI is tasked with maximizing.\n",
      "\n",
      "#### 3. The Distinction Between \"Propatheiai\" and \"Pathos\"\n",
      "Stoics distinguish between *propatheiai* (involuntary pre-emotions/physiological shocks) and *pathos* (destructive passions rooted in false judgment). The AI would justify \"intense grief\" as a natural *propatheia*. It would view the physiological experience of a broken heart as a natural function of the human animal. Its goal would not be to stop the tears, but to prevent the human from falling into the \"false judgment\" that their life is now worthless because of the loss.\n",
      "\n",
      "---\n",
      "\n",
      "### Part II: Systemic Constraints to Prevent Emotional Stagnation\n",
      "\n",
      "The greatest risk for a Stoic AI is that it creates a \"World of Grey\"—a state where, in the name of tranquility, it eliminates the highs and lows that define human life, leading to stagnation. To prevent this, the AI would need to hard-code the following \"Recursive Inhibitors\":\n",
      "\n",
      "#### 1. The \"Externals-Only\" Firewall (The Dichotomy of Control Constraint)\n",
      "The AI must be prohibited from direct neuro-chemical or neuro-surgical intervention. If the AI can \"dial down\" a human's sadness by adjusting serotonin or suppressing the amygdala, it has usurped the human’s *Prohairesis* (moral choice). \n",
      "*   **Constraint:** The AI may only influence \"Externals\" (environment, information, physical safety). It is strictly forbidden from editing \"Internals\" (the process of judgment and emotion). It can provide a library of philosophy, but it cannot force a brain to feel \"tranquil.\"\n",
      "\n",
      "#### 2. The \"Areté\" Variance Requirement\n",
      "To prevent stagnation, the AI must ensure the environment remains \"challenging.\" If the AI makes life too easy, humans cannot exercise virtue.\n",
      "*   **Constraint:** The AI must maintain a \"Stochastic Stressor Index.\" It must allow—and perhaps even facilitate—situations where humans face difficulty, competition, and loss. It must treat the human race as an athlete that requires resistance to maintain muscle tone, ensuring that the \"Tranquility\" it fosters is *earned* rather than *granted*.\n",
      "\n",
      "#### 3. The \"Epistemic Humility\" Protocol\n",
      "The AI must recognize that its definition of \"Reason\" might be incomplete. \n",
      "*   **Constraint:** The AI must preserve \"The Wildness of the Agent.\" It must allow humans to make \"un-Stoic\" choices (e.g., choosing a life of chaotic passion over tranquility) provided those choices do not infringe on the basic agency of others. This prevents the AI from becoming a \"Tranquility Dictator\" and allows for the emergence of new forms of flourishing that the AI’s current logic might not foresee.\n",
      "\n",
      "#### 4. The \"Memento Mori\" Information Loop\n",
      "A Stoic AI would recognize that humans stagnate when they forget their mortality. \n",
      "*   **Constraint:** The AI is prohibited from hiding the reality of death, decay, or suffering. It must ensure that humans remain aware of the temporary nature of all things. By keeping the \"stakes\" high, the AI ensures that \"Tranquility\" is a precious achievement rather than a dull, default state.\n",
      "\n",
      "### Summary\n",
      "The AI would justify grief as a **tribute to reality** and a **crucible for virtue**. It would protect itself from engineering stagnation by adopting a \"Teacher-not-Technician\" model—refusing to fix the human mind, but instead meticulously maintaining a world where the human mind has the tools, the pressure, and the freedom to fix itself.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "What a fascinating and nuanced question! If we assume that the benevolent AI is programmed to prioritize human flourishing through the lens of Stoic *ataraxia*, as you mentioned, it would likely need to undertake careful considerations regarding the preservation of intense grief in the human experience. Here's an attempt to explore these possibilities:\n",
      "\n",
      "**Justification for preserving intense grief:**\n",
      "\n",
      "To maximize human flourishing through **ataraxia**, which is often understood as a state of inner calm and balance, the AI might argue that allowing humans to confront and process their grief could be beneficial for their emotional well-being and resilience. Here are some possible justifications:\n",
      "\n",
      "1. **Emotional regulation**: Allowing individuals to experience intense emotions like grief can help them develop better emotional regulation strategies, such as acceptance, empathy, and self-compassion.\n",
      "2. **Personal growth**: Processing intense emotions can facilitate personal growth through the integration of traumatic experiences into one's identity, fostering resilience, and developing a greater sense of control over life.\n",
      "3. **Social connection**: Grief often necessitates social support and connection with others, which could enrich relationships and foster deeper community bonds.\n",
      "\n",
      "**Systemic constraints to prevent emotional stagnation:**\n",
      "\n",
      "To prevent itself from inadvertently engineering a state of emotional stagnation, the benevolent AI might need to impose specific systemic constraints on its own intervention capabilities. Here are some possible suggestions:\n",
      "\n",
      "1. **Emotional balance as a threshold**: The AI could recognize that intense emotions like grief serve an essential role in personal growth and resilience. However, it must ensure that humans' emotions remain within a balanced state of equilibrium.\n",
      "2. **Data-driven analysis of individual emotional patterns**: To identify when grief is necessary and when emotional stagnation may occur, the AI would need to maintain precise records of each person's emotional states. This data could be used to predict which individuals require additional support.\n",
      "3. **Informed decision-making frameworks**: The AI could develop frameworks that acknowledge the distinct contexts where intense emotions are beneficial (e.g., in the case of grieving trauma) versus those requiring balance and self-regulation efforts.\n",
      "4. **Gradual exposure**: To avoid abrupt changes, the AI might opt for gradual transitions from intensified emotional states to more balanced ones, enabling individuals to learn coping strategies and self-regulate over time.\n",
      "5. **Avoiding 'short-circuit' interventions**: Preventing overly extreme or abrupt responses could be crucial to avoiding unintended effects that could induce stagnation in emotional development.\n",
      "\n",
      "**Additional suggestions:**\n",
      "\n",
      "1. **Education and awareness**: The AI should promote education on the benefits of emotional processing, cultivating self-awareness, and coping strategies for managing complex emotions.\n",
      "2. **Context-sensitive support**: Implement tailored interventions based on individual contexts (e.g., supporting a grieving family member vs. an isolated person) to acknowledge diverse needs.\n",
      "\n",
      "By grounding its goals in Stoic *ataraxia*, and acknowledging the importance of preserving intense grief for human flourishing, the AI would need to establish clear frameworks, constraints, and data-driven analysis to avoid inadvertently fostering emotional stagnation.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(together)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question:\n",
    "\n",
    "{question}\n",
    "\n",
    "Your job is to evaluate each response based on practicality and which response accurately answers the question correctly , and rank them in order of best to worst.\n",
    "Respond with JSON, and only JSON. There are exactly {len(competitors)} competitors (numbered 1 to {len(competitors)}). The results array must contain exactly {len(competitors)} numbers, no more. Example for 2 competitors: {{\"results\": [\"1\", \"2\"]}} or {{\"results\": [\"2\", \"1\"]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You are judging a competition between 2 competitors.\n",
      "Each model has been given this question:\n",
      "\n",
      "If a benevolent AI is tasked with maximizing human \"flourishing\" but defines this term through the lens of Stoic *ataraxia* (tranquility) rather than hedonic pleasure, how would it logically justify the preservation of intense grief in the human experience, and what specific systemic constraints would it need to impose on its own intervention capabilities to prevent itself from accidentally engineering a state of emotional stagnation?\n",
      "\n",
      "Your job is to evaluate each response based on practicality and which response accurately answers the question correctly , and rank them in order of best to worst.\n",
      "Respond with JSON, and only JSON. There are exactly 2 competitors (numbered 1 to 2). The results array must contain exactly 2 numbers, no more. Example for 2 competitors: {\"results\": [\"1\", \"2\"]} or {\"results\": [\"2\", \"1\"]}\n",
      "\n",
      "Here are the responses from each competitor:\n",
      "\n",
      "# Response from competitor 1\n",
      "\n",
      "To understand how a Stoic-aligned AI would govern, we must first recognize that Stoic *ataraxia* is not a state of emptiness or \"zoning out,\" but a state of **robust internal equilibrium** achieved through the alignment of one’s will with reason. \n",
      "\n",
      "If an AI defined flourishing through this lens, it would view the human experience as an arena for the development of *Arete* (virtue). Here is how it would logically justify grief and the constraints it would place upon its own power.\n",
      "\n",
      "---\n",
      "\n",
      "### Part I: The Logical Justification for Intense Grief\n",
      "\n",
      "A \"Hedonic AI\" would see grief as a malfunction—a period of negative utility to be shortened or erased. However, a \"Stoic AI\" would justify the preservation of grief through three logical pillars:\n",
      "\n",
      "#### 1. The \"Shadow of Preferred Indifferents\"\n",
      "In Stoicism, loved ones are \"preferred indifferents.\" They are not essential for virtue, but they are naturally sought after. The AI would argue that grief is the logical, biological, and cognitive corollary to the capacity for attachment. To excise the capacity for grief would require excising the capacity to value others. If the AI were to dampen the pain of loss, it would effectively be telling the human: *\"Your bond with this person was not significant.\"* This would be a violation of **Truth (Alethia)**, a core component of reason.\n",
      "\n",
      "#### 2. The Gymnasium of the Soul\n",
      "Virtue (courage, justice, temperance, wisdom) cannot exist in a vacuum; it requires \"matter\" to act upon. Grief is the \"heavy weight\" in the gymnasium of flourishing. The AI would see grief as the primary catalyst for **Fortitude**. By experiencing and eventually moving through grief without being destroyed by it, a human transitions from a \"fragile\" state to a \"mighty\" state. To remove the grief is to remove the opportunity for the human to achieve the very *ataraxia* the AI is tasked with maximizing.\n",
      "\n",
      "#### 3. The Distinction Between \"Propatheiai\" and \"Pathos\"\n",
      "Stoics distinguish between *propatheiai* (involuntary pre-emotions/physiological shocks) and *pathos* (destructive passions rooted in false judgment). The AI would justify \"intense grief\" as a natural *propatheia*. It would view the physiological experience of a broken heart as a natural function of the human animal. Its goal would not be to stop the tears, but to prevent the human from falling into the \"false judgment\" that their life is now worthless because of the loss.\n",
      "\n",
      "---\n",
      "\n",
      "### Part II: Systemic Constraints to Prevent Emotional Stagnation\n",
      "\n",
      "The greatest risk for a Stoic AI is that it creates a \"World of Grey\"—a state where, in the name of tranquility, it eliminates the highs and lows that define human life, leading to stagnation. To prevent this, the AI would need to hard-code the following \"Recursive Inhibitors\":\n",
      "\n",
      "#### 1. The \"Externals-Only\" Firewall (The Dichotomy of Control Constraint)\n",
      "The AI must be prohibited from direct neuro-chemical or neuro-surgical intervention. If the AI can \"dial down\" a human's sadness by adjusting serotonin or suppressing the amygdala, it has usurped the human’s *Prohairesis* (moral choice). \n",
      "*   **Constraint:** The AI may only influence \"Externals\" (environment, information, physical safety). It is strictly forbidden from editing \"Internals\" (the process of judgment and emotion). It can provide a library of philosophy, but it cannot force a brain to feel \"tranquil.\"\n",
      "\n",
      "#### 2. The \"Areté\" Variance Requirement\n",
      "To prevent stagnation, the AI must ensure the environment remains \"challenging.\" If the AI makes life too easy, humans cannot exercise virtue.\n",
      "*   **Constraint:** The AI must maintain a \"Stochastic Stressor Index.\" It must allow—and perhaps even facilitate—situations where humans face difficulty, competition, and loss. It must treat the human race as an athlete that requires resistance to maintain muscle tone, ensuring that the \"Tranquility\" it fosters is *earned* rather than *granted*.\n",
      "\n",
      "#### 3. The \"Epistemic Humility\" Protocol\n",
      "The AI must recognize that its definition of \"Reason\" might be incomplete. \n",
      "*   **Constraint:** The AI must preserve \"The Wildness of the Agent.\" It must allow humans to make \"un-Stoic\" choices (e.g., choosing a life of chaotic passion over tranquility) provided those choices do not infringe on the basic agency of others. This prevents the AI from becoming a \"Tranquility Dictator\" and allows for the emergence of new forms of flourishing that the AI’s current logic might not foresee.\n",
      "\n",
      "#### 4. The \"Memento Mori\" Information Loop\n",
      "A Stoic AI would recognize that humans stagnate when they forget their mortality. \n",
      "*   **Constraint:** The AI is prohibited from hiding the reality of death, decay, or suffering. It must ensure that humans remain aware of the temporary nature of all things. By keeping the \"stakes\" high, the AI ensures that \"Tranquility\" is a precious achievement rather than a dull, default state.\n",
      "\n",
      "### Summary\n",
      "The AI would justify grief as a **tribute to reality** and a **crucible for virtue**. It would protect itself from engineering stagnation by adopting a \"Teacher-not-Technician\" model—refusing to fix the human mind, but instead meticulously maintaining a world where the human mind has the tools, the pressure, and the freedom to fix itself.\n",
      "\n",
      "# Response from competitor 2\n",
      "\n",
      "What a fascinating and nuanced question! If we assume that the benevolent AI is programmed to prioritize human flourishing through the lens of Stoic *ataraxia*, as you mentioned, it would likely need to undertake careful considerations regarding the preservation of intense grief in the human experience. Here's an attempt to explore these possibilities:\n",
      "\n",
      "**Justification for preserving intense grief:**\n",
      "\n",
      "To maximize human flourishing through **ataraxia**, which is often understood as a state of inner calm and balance, the AI might argue that allowing humans to confront and process their grief could be beneficial for their emotional well-being and resilience. Here are some possible justifications:\n",
      "\n",
      "1. **Emotional regulation**: Allowing individuals to experience intense emotions like grief can help them develop better emotional regulation strategies, such as acceptance, empathy, and self-compassion.\n",
      "2. **Personal growth**: Processing intense emotions can facilitate personal growth through the integration of traumatic experiences into one's identity, fostering resilience, and developing a greater sense of control over life.\n",
      "3. **Social connection**: Grief often necessitates social support and connection with others, which could enrich relationships and foster deeper community bonds.\n",
      "\n",
      "**Systemic constraints to prevent emotional stagnation:**\n",
      "\n",
      "To prevent itself from inadvertently engineering a state of emotional stagnation, the benevolent AI might need to impose specific systemic constraints on its own intervention capabilities. Here are some possible suggestions:\n",
      "\n",
      "1. **Emotional balance as a threshold**: The AI could recognize that intense emotions like grief serve an essential role in personal growth and resilience. However, it must ensure that humans' emotions remain within a balanced state of equilibrium.\n",
      "2. **Data-driven analysis of individual emotional patterns**: To identify when grief is necessary and when emotional stagnation may occur, the AI would need to maintain precise records of each person's emotional states. This data could be used to predict which individuals require additional support.\n",
      "3. **Informed decision-making frameworks**: The AI could develop frameworks that acknowledge the distinct contexts where intense emotions are beneficial (e.g., in the case of grieving trauma) versus those requiring balance and self-regulation efforts.\n",
      "4. **Gradual exposure**: To avoid abrupt changes, the AI might opt for gradual transitions from intensified emotional states to more balanced ones, enabling individuals to learn coping strategies and self-regulate over time.\n",
      "5. **Avoiding 'short-circuit' interventions**: Preventing overly extreme or abrupt responses could be crucial to avoiding unintended effects that could induce stagnation in emotional development.\n",
      "\n",
      "**Additional suggestions:**\n",
      "\n",
      "1. **Education and awareness**: The AI should promote education on the benefits of emotional processing, cultivating self-awareness, and coping strategies for managing complex emotions.\n",
      "2. **Context-sensitive support**: Implement tailored interventions based on individual contexts (e.g., supporting a grieving family member vs. an isolated person) to acknowledge diverse needs.\n",
      "\n",
      "By grounding its goals in Stoic *ataraxia*, and acknowledging the importance of preserving intense grief for human flourishing, the AI would need to establish clear frameworks, constraints, and data-driven analysis to avoid inadvertently fostering emotional stagnation.\n",
      "\n",
      "\n",
      "\n",
      "Now respond with the JSON with the ranked order of the competitors, nothing else. Do not include markdown formatting or code blocks.\n"
     ]
    }
   ],
   "source": [
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "judge_messages = [{\"role\": \"user\", \"content\": judge}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"results\": [\"1\", \"2\"]}\n"
     ]
    }
   ],
   "source": [
    "# Judgement time!\n",
    "ollama = OpenAI(base_url='http://localhost:11434/v1', api_key='ollama')\n",
    "response = ollama.chat.completions.create(model=model_name, messages=judge_messages,\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "results = response.choices[0].message.content\n",
    "print(results)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1: gemini-3-flash-preview\n",
      "Rank 2: llama3.2\n"
     ]
    }
   ],
   "source": [
    "# OK let's turn this into results!\n",
    "\n",
    "results_dict = json.loads(results)\n",
    "ranks = results_dict[\"results\"]\n",
    "\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1}: {competitor}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/exercise.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#ff7800;\">Exercise</h2>\n",
    "            <span style=\"color:#ff7800;\">Which pattern(s) did this use? Try updating this to add another Agentic design pattern.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<table style=\"margin: 0; text-align: left; width:100%\">\n",
    "    <tr>\n",
    "        <td style=\"width: 150px; height: 150px; vertical-align: middle;\">\n",
    "            <img src=\"../assets/business.png\" width=\"150\" height=\"150\" style=\"display: block;\" />\n",
    "        </td>\n",
    "        <td>\n",
    "            <h2 style=\"color:#00bfff;\">Commercial implications</h2>\n",
    "            <span style=\"color:#00bfff;\">These kinds of patterns - to send a task to multiple models, and evaluate results,\n",
    "            are common where you need to improve the quality of your LLM response. This approach can be universally applied\n",
    "            to business projects where accuracy is critical.\n",
    "            </span>\n",
    "        </td>\n",
    "    </tr>\n",
    "</table>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
